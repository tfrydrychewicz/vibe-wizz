# Wizz â€” AI-Native Second Brain for Engineering Managers

## Vision

Wizz is the operating system for an engineering manager's brain. It captures everything (meetings, notes, decisions, people context), connects it automatically, and surfaces the right information at the right time â€” so you spend less time organizing and more time leading.

## Design Principles

1. **Capture is effortless.** If it requires manual tagging, filing, or organizing, it's a bug.
2. **Context builds over time.** Every note, transcript, and interaction makes Wizz smarter. After 6 months, Wizz knows your org better than your wiki.
3. **AI acts, not just answers.** Wizz doesn't wait for queries â€” it proactively surfaces follow-ups, conflicts, and opportunities.
4. **Local-first, private by default.** Your management notes are sensitive. Data lives on your machine. Cloud is opt-in, only for AI inference.

## Target User

Senior engineering managers / directors managing 5-15 direct reports, multiple projects, and 15-30+ meetings/week. Primary platform: macOS. Primary languages: English and Polish.

---

## Tech Stack

| Layer | Technology | Rationale |
|-------|-----------|-----------|
| Shell | Electron + Vite | Cross-platform desktop, fast HMR |
| UI | Vue 3 + Composition API | Reactive, lightweight |
| Editor | TipTap (ProseMirror) | Rich text, extensible, mention support |
| Local DB | SQLite + sqlite-vec | Zero-config, embedded, vector search |
| FTS | SQLite FTS5 | Built-in, fast, good enough for local |
| AI inference | Claude API (Sonnet for bulk, Opus for synthesis) | Best reasoning, good multilingual |
| STT | ElevenLabs Scribe v2 Realtime (primary cloud) + Deepgram Nova-3 (secondary cloud) + macOS SFSpeechRecognizer via Swift (offline fallback) | Scribe v2: 99 languages, <150ms latency, Polish WER â‰¤5%; Deepgram: speaker diarization; SFSpeechRecognizer: fully offline, no API key |
| Native helper | Swift binary (mic detection) | CoreAudio metadata, no permissions needed |
| Sync (future) | CRDTs (Automerge) | Conflict-free multi-device sync |

### Why SQLite over PostgreSQL

PostgreSQL with pgvector is excellent server-side, but for a single-user desktop app:
- SQLite requires zero configuration, no daemon, no port management
- sqlite-vec provides HNSW vector search (cosine, L2) natively
- FTS5 handles full-text search without tsvector/GIN setup
- The entire database is a single file â€” trivial to backup, move, or restore
- Performance is more than sufficient for millions of rows on a single machine
- Users never see "connection refused" or need to run `pg_ctl start`

Keep PostgreSQL for the development/staging server if you build a cloud sync layer later.

---

## Data Model

### Core Tables

```
notes
â”œâ”€â”€ id (ULID)
â”œâ”€â”€ title
â”œâ”€â”€ body (rich text JSON â€” TipTap document)
â”œâ”€â”€ body_plain (extracted plain text for FTS)
â”œâ”€â”€ template_id? â†’ note_templates.id
â”œâ”€â”€ source (manual | transcript | daily_brief | import)
â”œâ”€â”€ language (detected, e.g. 'pl', 'en')
â”œâ”€â”€ created_at
â”œâ”€â”€ updated_at
â””â”€â”€ archived_at?

note_chunks
â”œâ”€â”€ id
â”œâ”€â”€ note_id â†’ notes.id
â”œâ”€â”€ chunk_text
â”œâ”€â”€ chunk_context (prepended context snippet for contextual retrieval)
â”œâ”€â”€ embedding (FLOAT[1536])  â€” via sqlite-vec
â”œâ”€â”€ layer (1=raw_chunk | 2=note_summary | 3=cluster_summary)
â”œâ”€â”€ position (ordering within note)
â””â”€â”€ created_at

entities
â”œâ”€â”€ id (ULID)
â”œâ”€â”€ name
â”œâ”€â”€ type_id â†’ entity_types.id
â”œâ”€â”€ fields (JSON â€” dynamic fields per type)
â”œâ”€â”€ created_at
â””â”€â”€ updated_at

entity_types
â”œâ”€â”€ id
â”œâ”€â”€ name (e.g. "Person", "Project", "OKR", "Decision")
â”œâ”€â”€ icon
â”œâ”€â”€ schema (JSON â€” field definitions with types)
â”œâ”€â”€ kanban_enabled (BOOLEAN)
â”œâ”€â”€ kanban_status_field (which field to use as kanban column)
â””â”€â”€ color

entity_mentions
â”œâ”€â”€ id
â”œâ”€â”€ note_id â†’ notes.id
â”œâ”€â”€ entity_id â†’ entities.id
â”œâ”€â”€ mention_type (manual | auto_detected)
â”œâ”€â”€ confidence (0.0-1.0, for auto-detected)
â”œâ”€â”€ char_offset_start
â”œâ”€â”€ char_offset_end
â””â”€â”€ created_at

note_relations
â”œâ”€â”€ id
â”œâ”€â”€ source_note_id â†’ notes.id
â”œâ”€â”€ target_note_id â†’ notes.id
â”œâ”€â”€ relation_type (references | follows_up | contradicts | supersedes)
â”œâ”€â”€ strength (0.0-1.0, cosine similarity)
â””â”€â”€ created_at

action_items
â”œâ”€â”€ id (ULID)
â”œâ”€â”€ title
â”œâ”€â”€ body?
â”œâ”€â”€ source_note_id â†’ notes.id
â”œâ”€â”€ assigned_entity_id? â†’ entities.id (Person)
â”œâ”€â”€ due_date?
â”œâ”€â”€ status (open | in_progress | done | cancelled)
â”œâ”€â”€ extraction_type (manual | ai_extracted)
â”œâ”€â”€ confidence (0.0-1.0)
â”œâ”€â”€ created_at
â””â”€â”€ completed_at?

calendar_events
â”œâ”€â”€ id
â”œâ”€â”€ external_id (Google/Outlook event ID)
â”œâ”€â”€ title
â”œâ”€â”€ start_at
â”œâ”€â”€ end_at
â”œâ”€â”€ attendees (JSON array of email/name)
â”œâ”€â”€ linked_note_id? â†’ notes.id
â”œâ”€â”€ transcript_note_id? â†’ notes.id
â”œâ”€â”€ recurrence_rule?
â””â”€â”€ synced_at

note_transcriptions
â”œâ”€â”€ id (UUID)
â”œâ”€â”€ note_id â†’ notes.id (ON DELETE CASCADE)
â”œâ”€â”€ started_at (ISO 8601 â€” when recording started)
â”œâ”€â”€ ended_at? (ISO 8601 â€” when recording stopped; null if session crashed)
â”œâ”€â”€ raw_transcript (TEXT â€” accumulated STT output)
â””â”€â”€ summary (TEXT â€” Claude Haiku-generated; written after recording ends; empty if AI fails or key not set)

daily_briefs
â”œâ”€â”€ id
â”œâ”€â”€ date
â”œâ”€â”€ content (generated markdown)
â”œâ”€â”€ calendar_snapshot (JSON)
â”œâ”€â”€ pending_actions_snapshot (JSON)
â”œâ”€â”€ generated_at
â””â”€â”€ acknowledged_at?
```

### FTS5 Virtual Table

```sql
CREATE VIRTUAL TABLE notes_fts USING fts5(
    title, body_plain,
    content='notes',
    content_rowid='rowid',
    tokenize='unicode61'
);
```

### Vector Index (sqlite-vec)

```sql
-- Raw chunk embeddings
CREATE VIRTUAL TABLE chunk_embeddings USING vec0(
    id INTEGER PRIMARY KEY,
    embedding FLOAT[1536] distance_metric=cosine
);

-- Note summary embeddings (Layer 2)
CREATE VIRTUAL TABLE summary_embeddings USING vec0(
    id INTEGER PRIMARY KEY,
    embedding FLOAT[1536] distance_metric=cosine
);

-- Cluster summary embeddings (Layer 3)
CREATE VIRTUAL TABLE cluster_embeddings USING vec0(
    id INTEGER PRIMARY KEY,
    embedding FLOAT[1536] distance_metric=cosine
);
```

### Schema Migration Policy

**All database schema changes must be delivered as migration files.** The app checks its schema version on every startup and applies pending migrations before the UI is shown.

- Migrations live in `src/main/db/migrations/`
- Each migration is a TypeScript file named `NNNN_description.ts` exporting a `Migration` object with `version` (integer), `name`, and `up(db)` function
- All migrations must be registered in `ALL_MIGRATIONS` in `src/main/db/migrations/index.ts`
- Applied migrations are tracked in the `schema_migrations` table (`version`, `name`, `applied_at`)
- **Adding a new table**: add `CREATE TABLE IF NOT EXISTS` to `SCHEMA_SQL` in `schema.ts` (for fresh installs) AND create a migration (for existing installs)
- **Adding a column to an existing table**: create a migration file only â€” do NOT touch `schema.ts`
- No `down()` / rollback â€” local-first single-user desktop app
- Current migrations: `0001` (`entities.trashed_at`), `0002` (`action_items.updated_at`)

---

## Feature Specifications

### 1. Notes â€” The Core Primitive

**Editor**: TipTap-based rich text editor with:
- Markdown shortcuts (# for headings, - for lists, ``` for code blocks)
- `@` mention for entities (autocomplete from entity index)
- `[[` for note linking (wiki-style, autocomplete from note titles)
- `/` slash commands (insert template, create entity, add action item, insert date)
- Inline code blocks with syntax highlighting
- Drag-and-drop image embedding (stored locally in app data)
- **Tables**: Insert 3Ã—3 table via toolbar (Table2 button); right-click any table cell for a context menu (add/delete row or column, delete table, merge/split cells); column resize handles; GFM tables from AI chat rendered correctly
- **AI inline generation** (two entry points):
  - *Space on empty line*: pressing `Space` at the start of a completely empty paragraph opens `AIPromptModal` in insert mode; a "Type Space for AI" hint appears on the focused empty line when the note has content (`AILinePlaceholder` extension via ProseMirror decoration); on submit the empty paragraph is replaced with AI-generated content
  - *Selection bubble menu*: selecting text or a table shows a floating `BubbleMenu` (TipTap v3 / Floating UI) with a sparkles AI button; clicking it opens `AIPromptModal` in replace mode with the selected text pre-loaded as context; on submit the selection is replaced with AI-generated content
  - Both modes call the `notes:ai-inline` IPC handler: FTS5 keyword search on the prompt (top 5 notes for context) + `generateInlineContent()` (Claude Haiku, `max_tokens 1500`) + `parseMarkdownToTipTap()` â†’ TipTap JSON nodes inserted/replacing via `deleteRange` + `insertContentAt` (single undo step); returns `{ error }` if no Anthropic API key

**Auto-save**: Debounced 500ms after last keystroke. No save button.

**Templates**: Users define note templates with:
- Predefined sections (e.g., "1:1 Template" â†’ Agenda / Updates / Action Items / Notes)
- Pre-linked entity type (e.g., "1:1 with @Person" auto-prompts for person selection)
- Optional auto-creation trigger (e.g., "create from calendar event matching '1:1'")

**Background Processing** (on save, async):
1. Extract plain text â†’ update FTS5 index
2. Chunk text (300-500 tokens, 50-token overlap) with contextual prefixes
3. Generate embeddings via Claude API (batch)
4. Auto-detect entity mentions (NER via Claude Haiku â€” fast, cheap)
5. Generate note summary (Layer 2) via Claude Sonnet
6. Detect and create note_relations based on entity overlap + embedding similarity
7. Extract action items via Claude Sonnet (if note source is transcript or contains action-like language)

### 2. Entities â€” Your Org Knowledge Graph

**Built-in Types** (pre-configured, user can modify):

| Type | Default Fields | Auto-detection |
|------|---------------|----------------|
| Person | name, role, team, email, manager, reports_to | Names in transcripts |
| Project | name, status, lead (â†’Person), team, priority | Project names in notes |
| Team | name, lead (â†’Person), members (â†’Person[]) | Team references |
| Decision | title, date, context_note (â†’Note), status, owner (â†’Person) | "We decided..." patterns |
| OKR | title, quarter, owner (â†’Person), key_results (text[]), status | OKR/goal mentions |

**Auto-enrichment**: When a Person entity is created with just a name, Wizz watches future notes/transcripts and progressively fills in role, team, email, preferences, communication style â€” surfacing suggestions for user confirmation.

**Entity Pages**: Each entity has a page showing:
- All fields
- Timeline of all notes/transcripts mentioning this entity (chronological)
- Related entities (co-mentioned, linked via fields)
- Open action items assigned to this entity
- AI-generated summary: "What I know about [entity]" â€” synthesized from all mentions

### 3. Meeting Transcription Pipeline

#### Detection (existing Swift binary â€” keep as-is)

Native Swift binary polls CoreAudio every 1s. On `mic_active`, Electron shows a frameless prompt:
- **Transcribe this meeting** (one-time)
- **Always transcribe** (auto for future)
- **Skip**

If calendar integration is active, the prompt shows the matching calendar event title.

#### Audio Capture

On user confirmation, Wizz activates the configured transcription backend and â€” when **System Audio Capture** is enabled â€” simultaneously launches the `AudioCapture.app` binary that mixes system output + microphone into one PCM stream:

1. **Microphone only** (default): renderer captures mic via `getUserMedia` and sends chunks to the cloud STT service
2. **System Audio Capture** (opt-in, requires macOS 14.2+): `AudioCapture.app` captures both system output (Zoom/Meet remote participants) and the local microphone, mixes them, and streams them to the cloud STT service â€” the renderer captures no audio itself

#### System Audio Capture â€” `AudioCapture.app`

`AudioCapture.app` is a Swift `.app` bundle (`swift/AudioCapture/Sources/main.swift`) packaged under `resources/AudioCapture.app/Contents/MacOS/AudioCapture`. Built with `npm run build:audiocapture`.

**Capture approach â€” ScreenCaptureKit SCStream:**

Wizz uses Apple's `ScreenCaptureKit` framework (`SCStream` with `capturesAudio=true`) to tap system audio output, which is the officially supported macOS API for capturing what plays through speakers/headphones during Zoom/Meet calls. A separate `AVAudioEngine` captures the microphone input.

This approach was chosen over Core Audio Taps (`AudioHardwareCreateProcessTap`) for its stability; SCStream is the Apple-supported way to get system audio on macOS 13+.

**Binary architecture:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AudioCapture.app (Swift binary â€” runs as child of main proc)  â”‚
â”‚                                                                 â”‚
â”‚  SCStream (capturesAudio=true)    AVAudioEngine.inputNode       â”‚
â”‚   â”œâ”€â”€ Float32 PCM (any rate/ch)    â”œâ”€â”€ Float32 PCM (native fmt) â”‚
â”‚   â””â”€â”€ resample â†’ 16kHz mono        â””â”€â”€ resample â†’ 16kHz mono   â”‚
â”‚            â”‚   appendSysAudio()              â”‚  appendMicAudio() â”‚
â”‚            â–¼                                â–¼                   â”‚
â”‚   sysBuf[32768]  (sysPos)       micBuf[32768]  (micPos)        â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ NSLock (bufLock) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                 â”‚                               â”‚
â”‚   DispatchSourceTimer (256ms)   â”‚                               â”‚
â”‚   â”œâ”€â”€ sysF = min(sysPos, 4096)  â”‚                               â”‚
â”‚   â”œâ”€â”€ micF = min(micPos, 4096)  â”‚                               â”‚
â”‚   â”œâ”€â”€ outBuf[max(sysF, micF)]   â”‚                               â”‚
â”‚   â”œâ”€â”€ outBuf += sysBuf[0..sysF] + micBuf[0..micF] (additive)  â”‚
â”‚   â”œâ”€â”€ compact each buffer independently                         â”‚
â”‚   â”œâ”€â”€ attenuate Ã— 0.6, clamp, convert to Int16                  â”‚
â”‚   â””â”€â”€ emit {"type":"audio_chunk","data":"<base64 PCM Int16>"}  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key design decision â€” separate buffers:**

Each audio source has its own ring buffer (`sysBuf`/`sysPos` for SCStream, `micBuf`/`micPos` for AVAudioEngine). The timer mixes them additively at drain time. This prevents the "sequential overflow" bug: if both sources write to a single shared buffer, their combined input rate (~32kHz effective) doubles the drain rate (~16kHz/256ms), filling the buffer in ~2 seconds and silently dropping all subsequent audio.

**Resampling:**

SCStream may deliver audio at the native device rate (e.g. 48kHz stereo) regardless of the requested 16kHz. A windowed box-filter averages input samples over each output sample's window (`halfW = max(0.5, ratio * 0.5)`) for anti-aliased downsampling. Fast path for already-16kHz mono audio (common when SCStream honors the configuration).

**Protocol (stdout JSON lines):**

| Message | Meaning |
|---------|---------|
| `{"type":"ready"}` | Binary started, both streams active |
| `{"type":"audio_chunk","data":"<base64>"}` | 256ms PCM Int16 16kHz mono chunk |
| `{"type":"error","message":"..."}` | Fatal error (permission denied, etc.) |

**Requirements:**
- macOS 14.2+ (SCStream audio on 13+; the setting is shown for 14.2+ to be safe)
- "Screen & System Audio Recording" permission (TCC: `NSScreenCaptureUsageDescription`)
- `NSMicrophoneUsageDescription` for AVAudioEngine mic access
- Both keys declared in `swift/AudioCapture/Info.plist` and in `mac.extendInfo` in `package.json`

**TypeScript wrapper** (`src/main/transcription/audioCapture.ts`):
- Spawns binary, parses stdout JSON lines, resolves `startAudioCapture()` promise on `ready`
- Calls `onChunk(Buffer)` for each PCM chunk; routes chunk to active WS backend
- `stopAudioCapture()` sends SIGTERM; binary flushes and exits cleanly
- Rejects promise (surfaces as `transcriptionError` in NoteEditor) if binary not found, crashes, or emits error before ready

**Integration with transcription backends when `system_audio_capture = 'true'`:**

| Backend | WS URL change | Chunk routing |
|---------|--------------|---------------|
| ElevenLabs realtime | none | `onChunk` sends `{message_type:'input_audio_chunk', audio_base_64: buf.toString('base64')}` |
| ElevenLabs batch | none | `onChunk` pushes `buf` into `batchAudioChunks[]` |
| Deepgram | `encoding=linear16&sample_rate=16000` added | `onChunk` sends raw Buffer bytes |
| macOS Swift | N/A (mic captured inside binary) | N/A |

Returns `audioFormat: 'system-audio'` from `transcription:start` â†’ renderer skips `getUserMedia` entirely.

#### Transcription Backends

Backend is selected automatically at session start based on which API keys are set in Settings (AI section):

**Tier 1 â€” ElevenLabs Scribe v2 Realtime** (when `elevenlabs_api_key` is set; takes priority over Deepgram)
- WebSocket: `wss://api.elevenlabs.io/v1/speech-to-text/realtime?model_id=scribe_v2_realtime[&language=xx]`
- Auth: `xi-api-key` header; audio sent as base64-encoded PCM 16kHz Int16 JSON messages
- Message format: `{ message_type: "input_audio_buffer.append", audio_base_64: "<base64>" }`
- Stop gracefully: send `{ message_type: "input_audio_buffer.commit" }`, wait 500ms, then close
- Events: `partial_transcript` â†’ live preview; `committed_transcript` â†’ accumulated to final
- 99 languages including Polish (WER â‰¤5%), <150ms latency

**Tier 2 â€” Deepgram Nova-3** (when `deepgram_api_key` is set and ElevenLabs key is absent)
- WebSocket: `wss://api.deepgram.com/v1/listen` with `encoding=webm`, `language=multi` (or specific), `punctuate`, `diarize`, `smart_format`
- Audio sent as raw WebM/Opus binary chunks (250ms `MediaRecorder` slices)
- Speaker diarization available; strong multilingual coverage

**Tier 3 â€” macOS SFSpeechRecognizer** (offline fallback; used when neither cloud key is set)
- Spawns `resources/Transcriber.app/Contents/MacOS/Transcriber` bundle (build with `npm run build:transcriber`)
- On-device Apple SFSpeechRecognizer; no API key required; works fully offline
- Language mapped from `transcription_language` setting via `LOCALE_MAP` in `swiftTranscriber.ts`
- Emits JSON lines (`ready`, `partial`, `error`) on stdout; graceful SIGTERM shutdown with up to 5s wait for final result

**Audio capture path per backend:**

| Backend | `system_audio_capture` | Renderer capture | IPC payload | Main â†’ service |
|---------|----------------------|-----------------|-------------|----------------|
| ElevenLabs | `'false'` | `ScriptProcessorNode` (PCM 16kHz Int16) | `ArrayBuffer` | base64 JSON message |
| ElevenLabs | `'true'` | none | â€” | `AudioCapture.app` chunks via `onChunk` |
| Deepgram | `'false'` | `MediaRecorder` (WebM/Opus, 250ms) | `ArrayBuffer` | raw binary |
| Deepgram | `'true'` | none | â€” | `AudioCapture.app` chunks via `onChunk` (PCM WS) |
| Swift | either | none (binary accesses mic directly) | â€” | â€” |

`transcription:start` returns `{ ok, audioFormat }` where `audioFormat` is `'pcm'` (ElevenLabs mic-only), `'webm'` (Deepgram mic-only), `'none'` (Swift), or `'system-audio'` (AudioCapture.app active for either cloud backend), signaling the renderer which capture path to activate.

**Transcription Settings:**

| Setting key | Purpose | Default |
|-------------|---------|---------|
| `elevenlabs_api_key` | ElevenLabs Scribe v2 API key (tier 1) | â€” |
| `deepgram_api_key` | Deepgram Nova-3 API key (tier 2) | â€” |
| `transcription_language` | Language code (`multi`, `pl`, `en`, etc.) | `multi` |
| `system_audio_capture` | `'true'`/`'false'` â€” enable `AudioCapture.app` (macOS 14.2+, ElevenLabs/Deepgram only) | `'false'` |
| `save_debug_audio` | `'true'`/`'false'` â€” save each session's audio to `{userData}/debug-audio/` as WAV or WebM | `'false'` |

#### Live Note-Taking During Transcription

While a transcription session is active and linked to a note, the NoteEditor remains fully editable â€” the user can type notes, action items, or observations in real time alongside the live transcript. The **Transcriptions panel** (persistent, below the editor body) displays the live partial transcript stream during recording. After recording stops, the panel transitions seamlessly to show all stored sessions from `note_transcriptions` in reverse chronological order â€” each session as a collapsible row with timestamp, duration, AI summary, and expandable raw transcript. A note can be transcribed multiple times (start/stop cycles); every session is preserved.

#### Post-Meeting Processing

When meeting ends (mic deactivates for >60s or user manually stops):

1. **Merge transcript + manual notes**: the raw transcript (streamed from the active STT backend) and the user's hand-typed note content are merged into a single unified note. The merge strategy:
   - Manual notes take precedence and appear first (the user's intent is preserved)
   - Processed transcript (AI-structured: summary, topics, decisions) is appended as a distinct section (e.g. `## Transcript Summary`) so it's clearly attributed
   - Raw verbatim transcript stored separately (accessible but collapsed by default)
2. **Speaker labeling**: Match diarized speakers to Person entities using voice profile (built over time) or calendar attendee list
3. **AI processing** (Claude Sonnet, single pass):
   - Generate structured meeting summary (topics discussed, decisions made, open questions)
   - Extract action items with assignees and deadlines
   - Detect new entities mentioned (people, projects) â†’ suggest creation
   - Identify follow-ups needed
4. **Action items** auto-created in `action_items` table, linked to source note
5. **Notification**: Desktop notification with summary + "Review notes" link

### 4. AI-Powered Retrieval (RAPTOR+)

#### Storage Layers (unchanged from original, adapted for SQLite)

| Layer | Content | Embedding Table | Refresh |
|-------|---------|----------------|---------|
| L1 â€” Chunks | 300-500 token chunks with contextual prefix | chunk_embeddings | On note save |
| L2 â€” Note summaries | LLM-generated, one per note | summary_embeddings | On note save |
| L3 â€” Cluster summaries | K-means clusters of related notes, LLM-summarized | cluster_embeddings | Nightly batch job |

#### Search Flow

```
User query
    â”‚
    â”œâ”€ Step 1: Query expansion (Claude Haiku)
    â”‚   "what do I know about microservices" â†’
    â”‚   ["microservices", "service mesh", "API gateway", "distributed systems"]
    â”‚
    â”œâ”€ Step 2: Parallel search
    â”‚   â”œâ”€ FTS5 keyword search on notes_fts
    â”‚   â”œâ”€ Vector search on cluster_embeddings (L3, top 5)
    â”‚   â”‚   â””â”€ Drill into summary_embeddings (L2, top 10 per cluster)
    â”‚   â”‚       â””â”€ Drill into chunk_embeddings (L1, top 5 per summary)
    â”‚   â””â”€ Graph traversal: follow note_relations from initial hits
    â”‚
    â”œâ”€ Step 3: Reciprocal Rank Fusion
    â”‚   Merge results from FTS, vector, and graph with RRF scoring
    â”‚
    â”œâ”€ Step 4: Re-rank (Claude Haiku)
    â”‚   Score each candidate chunk for relevance to original query
    â”‚
    â””â”€ Step 5: Synthesize (Claude Sonnet)
        Generate answer with citations [Note: "1:1 with Sarah, March 5"]
```

#### Proactive Retrieval (not query-driven)

While the user is writing a note, Wizz runs background retrieval:
- Every 10s (debounced), embed the current note content
- Find related notes via vector similarity
- Show a subtle sidebar: "Related: [Note title] â€” [1-line summary]"
- This creates serendipitous connections the user wouldn't have searched for

### 5. The Daily Brief

Every morning (configurable time, default 8:00), Wizz generates a briefing:

**Inputs:**
- Today's calendar events (from synced calendar)
- Open action items (sorted by due date)
- Overdue action items (flagged)
- Notes from the previous day
- Upcoming 1:1s this week + historical context for each person
- Any unacknowledged items from previous briefs

**Output** (generated by Claude Sonnet):

```markdown
# Tuesday, March 5 â€” Your Day

## ğŸ”¥ Needs Attention
- **Overdue**: Ship Bifrost migration plan (promised to @Sarah, Feb 28)
- **Today**: OKR review presentation at 2pm â€” last updated 2 weeks ago

## ğŸ“… Today's Meetings
- 9:00  Standup (Platform Team) â€” @Bartek flagged a blocker yesterday
- 10:30 1:1 with @Sarah â€” Topics from last time: promotion timeline,
        on-call rotation concerns. She had an action item to draft the
        new runbook.
- 14:00 OKR Review â€” You're presenting Platform team Q1 results
- 16:00 1:1 with @Bartek â€” Last 1:1 was Jan 28 (5 weeks ago âš ï¸)

## âœ… Action Items Due This Week
- [ ] Review @Sasha's design doc for event pipeline (due Wed)
- [ ] Send headcount request to @Director (due Fri)
- [ ] Follow up with @John re: vendor evaluation (no due date, 3 weeks old)

## ğŸ’¡ Worth Revisiting
- You noted "revisit caching strategy after load test" on Feb 20 â€”
  load test completed yesterday per @Bartek's standup note.
```

The brief appears as a special note type, pinned to the top of the day view. Users can acknowledge items (removes from future briefs), snooze, or convert any line into an action item.

### 6. Action Items & Kanban

**Action items are first-class citizens, not a separate module.**

Sources:
- AI-extracted from meeting transcripts (auto)
- AI-extracted from notes (auto, with user confirmation)
- Manually created via `/action` slash command in any note
- Created from Daily Brief items

Every action item links back to its source note. This is critical â€” you can always trace "why does this task exist?"

**Kanban views** are configurable per entity type:
- Default: Action Items kanban (Open â†’ In Progress â†’ Done)
- Custom: Any entity type with `kanban_enabled` can have a board
- Filters: by assignee, by project, by due date range, by source note
- Drag-and-drop status changes

**Follow-up intelligence**: If an action item is assigned to a Person entity and hasn't been updated in N days (configurable, default 7), Wizz surfaces it in the Daily Brief with context: "Assigned to @Sarah on Feb 20 during Platform standup. No updates in 12 days."

### 7. Calendar Integration

#### 7a. Calendar View (`CalendarView.vue`) â€” Implemented

**Four view modes**, selectable from the toolbar and persisted to settings (`calendar_view_mode`):

| Mode | Columns | Range |
|------|---------|-------|
| Day | 1 | Single date |
| Work Week | 5 | Monâ€“Fri of current week |
| Week | 7 | Sunâ€“Sat of current week |
| Month | 7Ã—N | Full calendar month grid |

**Time grid** (Day / Work Week / Week):
- Spans 7amâ€“9pm (14 hours)
- Hour height is responsive: fills the scroll container, minimum 56px/hr
- Left gutter shows hour labels (7amâ€¦8pm in 12h format)
- Each day column is a separate scrollable vertical lane
- Today's column header shows the day number highlighted with a filled blue circle

**Interactions in time-grid views:**
- **Drag-to-create**: Click and drag on an empty slot â†’ blue dashed preview block grows as you drag â†’ on mouse-up opens `MeetingModal` in create mode with start/end pre-filled, snapped to `calendar_slot_duration` increments
- **Click event â†’ edit**: A stationary click (no drag) on an event block opens `MeetingModal` in edit mode
- **Drag-to-move**: Click and hold on an event block â†’ the original fades to 35% opacity, a dashed ghost follows the cursor across days and times â†’ on mouse-up the event is updated in place (optimistic) and `calendar-events:update` is called
- **Resize**: Bottom edge of every event block has a 6px resize handle (`ns-resize` cursor) â†’ drag to stretch/shrink the end time â†’ updated optimistically and persisted on mouse-up
- **Slot duration**: Snap granularity loaded from settings (`calendar_slot_duration`, default 30 min); all drag operations snap to this increment

**Month view:**
- 7-column grid; rows auto-sized to `minmax(90px, 1fr)`
- Days outside the current month shown at 35% opacity
- Each day cell shows event chips (title + start time); click chip â†’ edit modal; click empty cell â†’ create modal pre-filled to 9:00â€“10:00am
- Today's date number highlighted with filled blue circle

**Toolbar:**
- â† / â†’ navigation (previous/next day, week, or month depending on mode)
- "Today" button â€” jumps `currentDate` to now without changing view mode
- View mode switcher (segmented button group)
- "New" button â€” opens create modal with current timestamp

**Data fetching:** `calendar-events:list` called whenever `rangeStart`/`rangeEnd` computed values change (i.e., on navigation or mode switch). Local event list updated optimistically for move/resize; modal-saved events are upserted without a full reload.

---

#### 7b. Meeting Modal (`MeetingModal.vue`) â€” Implemented

Used for both creating and editing calendar events. Opened from `CalendarView` and (planned) other entry points.

**Fields:**
- **Title** â€” free text input, required; `Enter` submits
- **Date** â€” `<input type="date">`, YYYY-MM-DD
- **Start / End time** â€” `<input type="time">`, HH:MM; combined with date via `buildISO()` to produce a local-timezone ISO 8601 string (no `Z` suffix â€” stored as local time)
- **Attendees** â€” two modes depending on settings:
  - *Entity search mode* (when `attendee_entity_type_id` + `attendee_name_field` + `attendee_email_field` are all set in Settings): autocomplete searches entities of the configured type; selecting an entity reads `nameField` and `emailField` from the entity's field JSON; stored with `entity_id`
  - *Free-form mode* (default): separate Name + Email inputs, added on Enter or `+` button
  - Attendee chips show name (bold) + email; Ã— button removes; stored as JSON array in `calendar_events.attendees`

**Meeting Notes section** (edit mode only â€” hidden in create mode):
- If `linked_note_id` is set: shows the note title as a clickable link (opens the note, all 3 open modes supported via click modifiers) + an unlink `Ã—` button
- If no linked note: two options side by side:
  1. **"Create Meeting Notes"** dashed button â€” calls `notes:create` with title generated from `meeting_note_title_template` setting (default `{date} - {title}`, where `{date}` = long locale date string and `{title}` = event title), then calls `calendar-events:update` to link it, then emits `open-note` to open it in the active pane
  2. **"or attach existing noteâ€¦"** search input â€” FTS search via `notes:search`; selecting a result links it via `calendar-events:update` and persists immediately

**Save:** `calendar-events:create` (create mode) or `calendar-events:update` (edit mode) with all fields. Attendees serialised as JSON. Error shown inline below the form.

**Delete:** Two-step confirmation (Delete button â†’ "Delete this meeting? Yes / Cancel"). Calls `calendar-events:delete`.

**Settings that affect MeetingModal:**

| Setting key | Purpose | Fallback |
|-------------|---------|---------|
| `attendee_entity_type_id` | Entity type ID for attendee search | free-form mode |
| `attendee_name_field` | Field name for attendee name (`__name__` = entity primary name) | entity.name |
| `attendee_email_field` | Field name for attendee email | empty |
| `meeting_note_title_template` | Template for auto-generated note title | `{date} - {title}` |

---

#### 7c. Meeting Context Header in NoteEditor â€” Implemented

When a note is opened that has a calendar event linked to it (`calendar-events:get-by-note`), a non-editable header bar appears above the editor body showing:
- Event title
- Formatted time range (e.g. "Mon, Feb 25 Â· 10:00am â€“ 11:00am")
- Attendee chips (parsed from the event's JSON attendees array)
- **"Start Transcription" / "Stop" button** â€” second entry point for transcription (in addition to the meeting detection prompt); clicking "Start Transcription" invokes `transcription:start`, selects the appropriate backend based on configured API keys, and begins audio capture; button changes to "Stop" while active; visible whenever the note has a linked event (mic does not need to be active)
- **Transcriptions panel** (persistent, below the editor body): present whenever the note has any transcription history or an active recording session. During recording: shows the live partial transcript stream at the top. After recording ends (`transcription:complete`): reloads from `transcriptions:list` and renders all stored sessions as collapsible rows. Each row shows:
  - Start date/time and session duration
  - AI-generated summary (Claude Haiku, produced asynchronously after recording ends)
  - "Raw Transcript" expandable section with the full verbatim text
  - The most recent session auto-expands after each recording stops
  - Sessions are ordered newest-first; all are preserved (multi-session history per note)

This gives the note authoring context without needing to open the calendar, and lets users start transcription directly from their meeting notes while continuing to write by hand.

---

#### 7d. Meeting Detection Prompt (`MeetingPrompt.vue` + `meetingWindow.ts`) â€” Implemented

A frameless always-on-top `BrowserWindow` (320Ã—190px, `floating` level so it appears above fullscreen apps) managed by `meetingWindow.ts`.

**Trigger flow:**
1. Swift `MicMonitor` binary polls CoreAudio every 1s, emits JSON on stdout
2. `monitor.ts` parses events and fires `micEvents`
3. `meetingWindow.ts` listens: on `mic:active` starts a **5-second debounce** before showing the prompt (avoids false positives from brief mic activations); resets if mic goes inactive
4. If `auto_transcribe_meetings = 'true'` in settings, the prompt is skipped and transcription is triggered directly
5. On `mic:inactive` the prompt is hidden with a 250ms animation delay

**Prompt UI:**
- "Meeting detected" header with red mic icon + close button
- Microphone device name (or "Microphone active" if unknown)
- **Meeting dropdown** (`<select>`): fetches today's calendar events via `calendar-events:list` on each `mic:active` event; lists events as "Title (9:00amâ€“10:00am)"; "+ New Meeting" option always at the bottom
- **Auto-selection**: the dropdown auto-selects whichever event is **currently in progress** (now â‰¥ start && now â‰¤ end) or **starts within the next 10 minutes**; falls back to "+ New Meeting" if none qualify
- Action buttons: **Transcribe** Â· **Always transcribe** Â· **Skip**

**Actions:**
- **Skip / close Ã—**: sends `meeting-prompt:skip` IPC â†’ `dismissed = true`, window hides; dismissed flag resets on next `mic:active`
- **Transcribe**: if "+ New Meeting" is selected, creates a `calendar-events:create` entry titled "New Meeting" (start = now, end = now + 1hr) before firing `meeting-prompt:transcribe` IPC (transcription is a no-op until Phase 3.2)
- **Always transcribe**: same as Transcribe but also writes `auto_transcribe_meetings = 'true'` to settings; future mic activations skip the prompt entirely
- **Dismissed state**: once dismissed in a mic session (any of the three actions), the prompt won't reappear until the mic goes inactive and becomes active again

> **Two transcription entry points**: transcription can be started from (1) this meeting detection prompt (mic-triggered, automatic) or (2) the **"Start Transcription" button in the NoteEditor meeting context header** (manual, note-linked event). Both paths converge on the same transcription pipeline and IPC channel (`meeting-prompt:transcribe`). See Â§7c.

---

#### 7e. IPC Reference â€” Calendar

| Channel | Direction | Payload | Returns |
|---------|-----------|---------|---------|
| `calendar-events:list` | invoke | `{ start_at: ISO, end_at: ISO }` | `CalendarEvent[]` with `linked_note_title` via LEFT JOIN, ordered by `start_at` |
| `calendar-events:create` | invoke | `{ title, start_at, end_at, attendees?, linked_note_id? }` | full `CalendarEvent` row |
| `calendar-events:update` | invoke | `{ id, title?, start_at?, end_at?, attendees?, linked_note_id? }` | `{ ok }` (dynamic SET) |
| `calendar-events:delete` | invoke | `{ id }` | `{ ok }` (hard-delete) |
| `calendar-events:get-by-note` | invoke | `{ note_id }` | `CalendarEvent & { linked_note_title }` \| null |
| `meeting-prompt:skip` | send | â€” | hides prompt, sets dismissed |
| `meeting-prompt:transcribe` | send | â€” | hides prompt, triggers transcription (Phase 3.2) |
| `meeting-prompt:always-transcribe` | send | â€” | saves setting, hides prompt, triggers transcription |

**`CalendarEvent` type** (exported from `MeetingModal.vue`):
```ts
interface CalendarEvent {
  id: number                    // INTEGER PRIMARY KEY (not ULID)
  external_id: string | null    // future: Google/Outlook event ID
  title: string
  start_at: string              // ISO 8601 local time (no Z)
  end_at: string
  attendees: string             // raw JSON string â†’ AttendeeItem[]
  linked_note_id: string | null
  transcript_note_id: string | null
  recurrence_rule: string | null
  synced_at: string
  linked_note_title: string | null  // JOIN field, not in DB column
}
```

---

#### 7f. IPC Reference â€” Transcription

Transcription IPC channels registered in `src/main/transcription/session.ts`:

| Channel | Direction | Payload | Returns |
|---------|-----------|---------|---------|
| `transcription:start` | invoke | `{ noteId, eventId? }` | `{ ok, audioFormat: 'pcm'\|'webm'\|'none', error? }` |
| `transcription:stop` | invoke | â€” | `{ ok }` |
| `transcription:audio-chunk` | send | `ArrayBuffer` | â€” (one-way) |
| `transcription:status` | invoke | â€” | `{ isTranscribing, noteId }` |
| `transcription:partial` | push | `{ text, isFinal }` | â€” |
| `transcription:complete` | push | `{ noteId }` | â€” |
| `transcription:error` | push | `{ message }` | â€” |
| `transcription:open-note` | push | `{ noteId, eventId, autoStart }` | â€” |
| `transcriptions:list` | invoke | `{ noteId }` | `NoteTranscription[]` sorted by `started_at DESC` |

**`NoteTranscription` type:**
```ts
interface NoteTranscription {
  id: string
  note_id: string
  started_at: string        // ISO 8601
  ended_at: string | null
  raw_transcript: string
  summary: string           // empty string if AI unavailable
}
```

**`audioFormat` behaviour:**
- `'pcm'` â†’ renderer uses `ScriptProcessorNode` at 16kHz; chunks sent as `Int16Array` buffers
- `'webm'` â†’ renderer uses `MediaRecorder` (WebM/Opus, 250ms); chunks sent as raw binary
- `'none'` â†’ Swift binary captures mic internally; renderer sends no audio chunks
- `'system-audio'` â†’ `AudioCapture.app` is active; renderer skips `getUserMedia` entirely; `transcription:audio-chunk` IPC is a no-op

---

#### 7g. Planned (Future Phases)

- **Google Calendar / Outlook sync**: OAuth2 pull every 5 min, match attendees to Person entities by email; populate `external_id`, `recurrence_rule`
- **Meeting prep notifications**: desktop notification 5 min before event; click opens a prep note with AI-generated context from previous meetings with the same attendees
- **Smart linking**: suggest linking an open note to today's events; auto-link transcript to matching event by time overlap
- **Speaker diarization + entity matching** (deeper): match Deepgram/ElevenLabs diarized speakers to Person entities using voice profile (built over time); current implementation matches by calendar attendee name via Claude Haiku post-processing
- **Post-meeting action extraction from transcript**: dedicated transcript-aware extraction pass that runs after `postProcessor.ts`; extracts action items with assignees and deadlines, creates rows in `action_items`, links to source note

### 8. Command Palette & AI Chat

**Command Palette** (`Cmd+K`):
- Quick navigation to any note, entity, or view
- Fuzzy search across titles, entity names, recent items
- Action shortcuts: "New note", "New 1:1 with...", "Show today's brief"

**AI Chat Sidebar** (`Cmd+J`):
- Natural language queries against your knowledge base
- "What did we decide about the migration timeline?"
- "Summarize my last 3 meetings with the platform team"
- "Draft a status update for Project Bifrost based on this week's notes"
- "What are all of Sarah's open action items?"
- Answers include citations linking to source notes
- Conversation context persists within a session
- **Image attachments**: paste images from clipboard (`Cmd+V` in textarea) or drag-and-drop onto the sidebar; attached images appear as 64Ã—64px thumbnails in a bar above the input with a âœ• remove button; on send the images are forwarded to Claude as vision content blocks (base64, Anthropic Vision API); sent images are shown as 100Ã—100px thumbnails in the conversation history below the user's message bubble; supported formats: JPEG, PNG, GIF, WebP
- **Entity `@` mentions**: typing `@` in the chat input opens a floating entity picker (debounced search via `entities:search`, up to 8 results with name + type badge); selecting an entity inserts `@EntityName` at the cursor and adds a blue `@Name Â· TypeName` chip to the context bar; entity IDs are sent as `mentionedEntityIds` in `chat:send` â†’ main process fetches `EntityContext[]` (id, name, type_name) from DB â†’ injected into the system prompt as `[id:uuid] @Name (type: TypeName)` so Claude can correctly resolve entity IDs when assigning tasks, and validate that the entity type is appropriate for the operation

### 8a. AI Actions â€” Agentic Command Execution

**Overview**: The AI chat sidebar can execute Wizz operations directly from natural language. Instead of only answering questions, the assistant understands commands and performs them â€” creating meetings, updating action item statuses, rescheduling events â€” returning a confirmation alongside its prose response.

**Supported actions (initial scope):**

| Category | Operations | Example prompts |
|----------|-----------|-----------------|
| Calendar | create, update, delete | "Schedule a retro Friday at 3pm", "Move tomorrow's standup to 10am", "Cancel the 2pm sync" |
| Action items | create, update (title/status/due/assignee), delete | "Add a task: review Sasha's PR by Wednesday", "Mark the runbook task as done", "Assign the vendor eval to @John" |

**Intent detection â€” Claude tool use, not regex:**

`chat.ts` passes a set of tool definitions to the Claude API with every message. Claude decides autonomously whether to call a tool or reply conversationally â€” no keyword matching or separate intent classifier needed. The full set of defined tools:

```typescript
const WIZZ_TOOLS: Tool[] = [
  {
    name: 'create_calendar_event',
    description: 'Create a new calendar event.',
    input_schema: {
      type: 'object',
      properties: {
        title:     { type: 'string' },
        start_at:  { type: 'string', description: 'ISO 8601 local time, no Z' },
        end_at:    { type: 'string', description: 'ISO 8601 local time, no Z' },
        attendees: { type: 'array', items: { type: 'object', properties: { name: { type: 'string' }, email: { type: 'string' } } } }
      },
      required: ['title', 'start_at', 'end_at']
    }
  },
  {
    name: 'update_calendar_event',
    description: 'Update fields on an existing calendar event. Resolve event ID from context before calling.',
    input_schema: {
      type: 'object',
      properties: {
        id:       { type: 'number' },
        title:    { type: 'string' },
        start_at: { type: 'string' },
        end_at:   { type: 'string' },
        attendees: { type: 'array', items: { type: 'object' } }
      },
      required: ['id']
    }
  },
  {
    name: 'delete_calendar_event',
    description: 'Delete a calendar event. ALWAYS describe what you are about to delete and ask the user to confirm before calling this tool.',
    input_schema: {
      type: 'object',
      properties: { id: { type: 'number' } },
      required: ['id']
    }
  },
  {
    name: 'create_action_item',
    description: 'Create a new action item / task.',
    input_schema: {
      type: 'object',
      properties: {
        title:              { type: 'string' },
        due_date:           { type: 'string', description: 'ISO 8601 date' },
        assigned_entity_id: { type: 'string', description: 'Entity ID of the Person to assign' },
        source_note_id:     { type: 'string' }
      },
      required: ['title']
    }
  },
  {
    name: 'update_action_item',
    description: 'Update an existing action item. Resolve item ID from context before calling.',
    input_schema: {
      type: 'object',
      properties: {
        id:                 { type: 'string' },
        title:              { type: 'string' },
        status:             { type: 'string', enum: ['open', 'in_progress', 'done', 'cancelled'] },
        due_date:           { type: 'string' },
        assigned_entity_id: { type: 'string' }
      },
      required: ['id']
    }
  },
  {
    name: 'delete_action_item',
    description: 'Delete an action item. ALWAYS describe what you are about to delete and ask the user to confirm before calling this tool.',
    input_schema: {
      type: 'object',
      properties: { id: { type: 'string' } },
      required: ['id']
    }
  }
]
```

**Execution flow (single `chat:send` round-trip):**

```
User: "Schedule a retro on Friday at 3pm"
    â”‚
    â”œâ”€ Step 1: chat.ts sends messages[] + WIZZ_TOOLS to Claude
    â”‚
    â”œâ”€ Step 2: Claude responds stop_reason='tool_use'
    â”‚   tool_use: { name: 'create_calendar_event',
    â”‚               input: { title: 'Retro', start_at: '2026-02-27T15:00',
    â”‚                         end_at: '2026-02-27T16:00' } }
    â”‚
    â”œâ”€ Step 3: chat.ts executes the corresponding DB operation directly
    â”‚   (calls the same logic as calendar-events:create IPC handler)
    â”‚   result: { id: 42, title: 'Retro', ... }
    â”‚
    â”œâ”€ Step 4: result appended as tool_result message; loop back to Claude
    â”‚
    â””â”€ Step 5: Claude produces final response (stop_reason='end_turn')
        content: "Done! I've scheduled **Retro** for Friday Feb 27, 3â€“4pm."
        actions: [{ type: 'created_event', payload: { id: 42, title: 'Retro', ... } }]
```

The tool loop runs entirely inside `chat.ts` â€” `chat:send` still resolves with a single `{ content, references, actions }` response. Multi-tool turns (e.g. create then update) are handled by iterating until `stop_reason !== 'tool_use'`.

**Destructive action confirmation:**

Delete tools include in their `description` the instruction to always seek confirmation before calling. Claude will therefore respond conversationally ("Should I delete **Retro** on Friday?") when delete intent is detected. The user confirms ("yes, go ahead") and the delete executes on the next turn. If the user phrased the original command as an unambiguous delete ("yes delete that retro"), Claude may call the tool immediately on the first turn.

**`chat:send` response â€” extended type:**

```typescript
interface ExecutedAction {
  type:
    | 'created_event'   | 'updated_event'   | 'deleted_event'
    | 'created_action'  | 'updated_action'  | 'deleted_action'
  payload: CalendarEvent | ActionItem | { id: number | string }  // deleted: id only
}

interface ChatResponse {
  content: string
  references: { id: string; title: string }[]   // existing â€” note citations
  actions: ExecutedAction[]                       // new â€” executed tool results
}
```

No new IPC channel required. Tool execution is internal to the `chat:send` handler.

**ChatSidebar action cards:**

Executed actions are rendered as compact cards below the assistant's text message:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ…  Created event                         â”‚
â”‚  Retro Â· Fri Feb 27 Â· 3:00â€“4:00pm        â”‚
â”‚                              Open in Calendar â†’ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ…  Action item marked done               â”‚
â”‚  Review Sasha's PR                       â”‚
â”‚                              Open in Actions â†’ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ—‘  Deleted event                         â”‚
â”‚  Friday Retro                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Card colours: green for creates, blue for updates, muted red for deletes. "Open inâ€¦" buttons support all three navigation modes (plain / Shift / Cmd click).

**Resolving references from context:**

The system prompt already injects upcoming calendar events and open action items (see `chat:send` implementation). When the user says "move tomorrow's standup", Claude finds the matching event ID in the injected context and calls `update_calendar_event` with it directly. If multiple matches exist or the reference is ambiguous, Claude asks for clarification before calling any tool.

**Error handling:**

If a tool call fails (DB error, item not found), the error is returned as a `tool_result` with `is_error: true`. Claude sees the error text and responds naturally: "I couldn't find that meeting â€” can you tell me more about when it is?" The failed tool call is omitted from `actions[]` in the response.

---

### 9. Data Portability

**Import**:
- Markdown files (Obsidian vault, any .md collection)
- Notion export (HTML/Markdown)
- Apple Notes (via AppleScript export)
- CSV (for entity bulk import)

**Export**:
- Full database as SQLite file
- All notes as Markdown with YAML frontmatter
- All entities as JSON/CSV
- Meeting transcripts as timestamped text files

**Backup**: Automatic daily backup of SQLite file to user-configured location (local folder, iCloud Drive, etc.)

---

## Offline Behavior

| Feature | Online | Offline |
|---------|--------|---------|
| Note editing | âœ… | âœ… |
| FTS search | âœ… | âœ… |
| Vector search | âœ… (new embeddings) | âœ… (cached embeddings only) |
| Meeting transcription | âœ… (ElevenLabs / Deepgram) | âœ… (macOS SFSpeechRecognizer, on-device, no API key) |
| AI summaries / extraction | âœ… (Claude) | âŒ (queued for when online) |
| Daily Brief | âœ… | âŒ (generated when reconnected) |
| Calendar sync | âœ… | âœ… (cached events, no updates) |
| AI Chat | âœ… | âŒ |

Offline-created notes are queued for embedding/processing and handled automatically when connectivity is restored.

---

## UX Architecture

### Navigation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Sidebar                    Main Area             â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ğŸ“‹ Today   â”‚  â”‚                              â”‚ â”‚
â”‚ â”‚ ğŸ“ Notes   â”‚  â”‚  [Note Editor / Entity Page  â”‚ â”‚
â”‚ â”‚ ğŸ‘¥ People  â”‚  â”‚   / Kanban / Daily Brief /   â”‚ â”‚
â”‚ â”‚ ğŸ“ Projectsâ”‚  â”‚   AI Chat / Search Results]  â”‚ â”‚
â”‚ â”‚ âœ… Actions â”‚  â”‚                              â”‚ â”‚
â”‚ â”‚ ğŸ“… Calendarâ”‚  â”‚                              â”‚ â”‚
â”‚ â”‚ ğŸ” Search  â”‚  â”‚                              â”‚ â”‚
â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚  â”‚                              â”‚ â”‚
â”‚ â”‚ âš™ Settings â”‚  â”‚                              â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                  [Context Sidebar (optional)] â†’ â”‚ â”‚
â”‚                  Related notes / Entity details  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Today**: Daily Brief + today's calendar + recent notes
- **Notes**: All notes, filterable by template, date range, linked entities
- **People / Projects / etc.**: Entity list views (one per entity type)
- **Actions**: Action items list + kanban view
- **Calendar**: Week/day view with linked notes overlaid
- **Search**: AI-powered search + FTS results

### Key Interactions

- `Cmd+N` â€” New note
- `Cmd+K` â€” Command palette
- `Cmd+J` â€” AI chat sidebar
- `Cmd+Shift+T` â€” Today view
- `@` in editor â€” Entity mention
- `[[` in editor â€” Note link
- `/` in editor â€” Slash commands

---

## Implementation Phases

### Phase 1 â€” Foundation 
- [x] Electron + Vue + Vite scaffold
- [x] SQLite database with FTS5
- [x] TipTap note editor with auto-save
- [x] Basic note CRUD + list view
- [x] Entity types + entity CRUD
- [x] `@` mentions in editor
- [x] Add support for entity trash 
- [x] Add support for entity mention store
- [x] Add support for tabs and multi-pane view to the right pane
    - `SHIFT+click` on the item opens it in a new pane (support multiple panes in one tab)
    - `Command+click` on the item opens it in a new tab.
- [x] `[[` mentions in editor, allowing to mention a note, or create new one.
- [x] Note templates

### Phase 2 â€” Intelligence
- [x] sqlite-vec integration + embedding pipeline
- [x] Chunking + contextual retrieval
- [x] Claude integration for note summaries (L2)
- [x] FTS + vector hybrid search
- [x] Auto entity detection (NER)
- [x] Action item extraction from notes (also available on `/` command in the note)
- [x] AI chat sidebar (basic)

### Phase 3 â€” Meetings
- [x] Swift mic detection binary
- [x] Meetings + Meetings CRUD + Displaying meetings in the calendar
    - Meeting fields are editable
    - Calendar supports different views: single day, working days in the week, week, month
    - Drag-to-create, drag-to-move, resize events in time-grid views
    - Slot duration configurable in Settings; view mode persisted across sessions
- [x] Meeting detection prompt with today's meeting selector
    - Auto-selects the meeting in progress or starting within 10 minutes
    - "New Meeting" option creates a calendar event and links it to the transcription session
    - "Always transcribe" writes setting to skip the prompt on future mic activations
- [x] Meeting Notes â€” create or attach a note to a calendar event
    - "Create Meeting Notes" generates a note titled from `meeting_note_title_template` and links it
    - "Attach existing note" FTS search input links any existing note
    - Linked note shown as clickable chip in MeetingModal (all 3 open modes)
    - NoteEditor shows meeting context header (title, time, attendees) for notes linked to a calendar event
- [x] Attendee entity configuration in Settings
    - Choose entity type, name field, and email field for attendee autocomplete in MeetingModal
- [x] Multi-backend streaming transcription: ElevenLabs Scribe v2 Realtime (tier 1), Deepgram Nova-3 (tier 2), macOS SFSpeechRecognizer via Swift binary (tier 3 / offline) â€” triggered from meeting prompt **and** NoteEditor meeting context header; backend auto-selected based on configured API keys
- [x] Transcript â†’ structured note pipeline (`postProcessor.ts`: Claude Haiku summary + raw transcript appended as TipTap nodes to linked note; `note_transcriptions` row persisted per session; embedding pipeline triggered after)
- [x] Post-meeting summary (basic): Claude Haiku generates structured meeting summary (Meeting Summary / Key Decisions / Follow-ups); stored in `note_transcriptions.summary` and appended to note body
- [x] Multi-session transcription history: each start/stop cycle persists to `note_transcriptions`; Transcriptions panel in NoteEditor shows all sessions (newest-first) with timestamps, durations, AI summaries, and expandable raw transcripts
- [x] Speaker diarization + entity matching: Deepgram word-level `words` array parsed into speaker segments (`[Speaker N]: text`); on stop, calendar event attendee names fetched and passed to `postProcessor.ts`; Claude Haiku maps speaker IDs â†’ attendee names; labels replaced before storing `raw_transcript` and generating merged note
- [x] Post-meeting action extraction from transcript (action items currently extracted from note body by general pipeline; dedicated transcript-aware extraction pending)
- [x] System audio capture â€” `AudioCapture.app` Swift bundle using ScreenCaptureKit SCStream (system output) + AVAudioEngine (mic), separate buffers for each source, windowed-average resampler, 256ms PCM Int16 chunks to ElevenLabs/Deepgram; `system_audio_capture` setting in Settings â†’ AI (ElevenLabs/Deepgram tabs only); returns `audioFormat:'system-audio'` â†’ renderer skips `getUserMedia`; Deepgram opens PCM WebSocket variant (`encoding=linear16&sample_rate=16000`); `stopAudioCapture()` on `cleanupSession()`
- [x] WebSocket disconnect handling â€” `handleUnexpectedClose(code)` in `session.ts` called from all three WS close handlers (`openElevenLabsSocket`, `openDeepgramSocket`, `openDeepgramSocketPcm`); saves partial transcript and runs post-processing when server closes connection mid-session
- [x] Debug audio saving â€” `save_debug_audio` setting in Settings â†’ Debug tab; when enabled, PCM chunks (or WebM) collected during session and written as WAV/WebM to `{userData}/debug-audio/` on session end; `debug:open-audio-folder` IPC opens folder in Finder
- [ ] Meeting prep notifications
- [ ] Calendar sync (Google Calendar)

### Phase 4 â€” Proactive AI
- [x] Make the AI also aware of the meetings and actions
- [x] AI Actions â€” natural language calendar and action item CRUD via Claude tool use (Â§8a): extend `chat.ts` with `WIZZ_TOOLS` definitions + tool-call execution loop; extend `chat:send` response with `actions: ExecutedAction[]`; render action cards in `ChatSidebar.vue`
- [x] Image attachments in AI chat â€” paste from clipboard or drag-and-drop onto sidebar; thumbnail bar above input; images forwarded as Anthropic Vision base64 content blocks on the last user message; thumbnails shown in conversation history
- [x] Daily Brief generation
- [x] Cluster summaries (L3) + nightly batch â€” K-means++ on L2 summary embeddings (K=âˆš(N/2), 2â€“20), Claude Haiku cluster theme summaries, stored in `note_chunks(layer=3)` + `cluster_embeddings`; `scheduler.ts` runs at startup if >23h since last run; semantic search upgraded with +0.05 cluster boost on top of FTS5+L1 RRF
- [x] Graph RAG (note_relations) â€” after FTS5 seed retrieval in `chat:send`, walks 1-hop in the knowledge graph: bidirectional `[[wiki-link]]` neighbors via `note_relations` (up to 5, ranked by overlap count) + `@entity` co-occurrence neighbors via `entity_mentions` (up to 5); indexes added on `note_relations(source_note_id/target_note_id)`; system prompt updated to tell Claude context includes graph-connected notes; backlinks footer in `NoteEditor.vue` shows count of incoming `[[links]]` and expands to a clickable list (all 3 open modes) via new `notes:get-backlinks` IPC
- [x] Follow-up intelligence â€” `updated_at` column added to `action_items` (migration in `db/index.ts`); `action-items:update` stamps `updated_at` on every change; `dailyBrief.ts` reads `followup_staleness_days` (default 7) and `followup_assignee_entity_type_id` settings, filters stale open items assigned to entities of that type, injects a `STALE FOLLOW-UPS` section into the Daily Brief prompt; Settings â†’ AI â†’ "Follow-up Intelligence" subsection: pick assignee entity type + staleness threshold
- [x] Entity `@` mentions in AI chat â€” `@` trigger in chat textarea opens entity picker (floating dropdown, debounced `entities:search`, keyboard navigation); on select inserts `@Name` text and adds entity chip to context bar; chips persist for the session, can be removed manually; `chat:send` accepts `mentionedEntityIds?: string[]` â†’ main fetches `EntityContext[]` and passes to `sendChatMessage()` as new 8th param; Claude receives entity context block (`[id:uuid] @Name (type: TypeName)`) enabling it to assign tasks to correct entity IDs and validate entity types
- [x] Proactive related notes sidebar
- [x] Query expansion + re-ranking

### Phase 5 â€” Polish & Portability
- [x] Table support in editor â€” `@tiptap/extension-table*`; toolbar insert button; right-click context menu (`TableContextMenu.vue`) for add/delete row/col, delete table, merge/split cells; CellSelection preserved on right-click via `mousedown` guard; GFM table parsing in `postProcessor.ts` so AI-generated notes render tables correctly; system prompts updated with GFM table syntax
- [x] AI inline generation â€” Space on empty line + selection bubble menu (see Â§1 Editor above); `AIPromptModal.vue`, `AILinePlaceholder.ts` extension, `notes:ai-inline` IPC, `generateInlineContent()` in `chat.ts`
- [ ] Import (Markdown, Notion, CSV)
- [ ] Export (Markdown, JSON, SQLite)
- [ ] Automatic backups
- [ ] Improved offline mode (macOS SFSpeechRecognizer already implemented as tier 3 fallback; this item covers improving quality and on-device model selection)
- [ ] Kanban views
- [x] Keyboard shortcuts + command palette
- [ ] Performance optimization

---

## Risks & Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| System audio capture permission (Screen &amp; System Audio Recording) | User may deny TCC prompt | Graceful error surfaced in NoteEditor; mic-only fallback works without permission; `NSScreenCaptureUsageDescription` declared in `AudioCapture.app` Info.plist and `mac.extendInfo` |
| Claude API costs at scale (millions of chunks) | Expensive | Use Haiku for NER/re-ranking, Sonnet for synthesis; batch embeddings; cache aggressively |
| sqlite-vec maturity | Potential bugs | Keep pgvector as fallback path; sqlite-vec is actively maintained by Alex Garcia |
| STT API cost for heavy users | ~$0.01/min adds up | Three-tier fallback: ElevenLabs â†’ Deepgram â†’ macOS SFSpeechRecognizer (free, offline); users without API keys get working transcription at zero cost |
| Scope creep (notes + CRM + tasks + calendar + AI) | Never ships | Phase 1 is usable standalone; each phase adds value independently |
| Polish language STT accuracy | Core user need | ElevenLabs Scribe v2 WER â‰¤5% for Polish; SFSpeechRecognizer has strong Polish support on macOS 13+; test early with real recordings |
